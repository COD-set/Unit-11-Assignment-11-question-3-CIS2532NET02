{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb04ea2b",
   "metadata": {},
   "source": [
    "# Deep learning part 2 (convolutional neural network)\n",
    "we will be going though the following in this notebook:\n",
    "excploring and processing data\n",
    "building and training our convolutinal network\n",
    "testing with our own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b10a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get our data!\n",
    "import keras\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# we are going to be using Keras to actually build this architectrure. \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d24cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ddb948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[154 177 187]\n",
      "  [126 137 136]\n",
      "  [105 104  95]\n",
      "  ...\n",
      "  [ 91  95  71]\n",
      "  [ 87  90  71]\n",
      "  [ 79  81  70]]\n",
      "\n",
      " [[140 160 169]\n",
      "  [145 153 154]\n",
      "  [125 125 118]\n",
      "  ...\n",
      "  [ 96  99  78]\n",
      "  [ 77  80  62]\n",
      "  [ 71  73  61]]\n",
      "\n",
      " [[140 155 164]\n",
      "  [139 146 149]\n",
      "  [115 115 112]\n",
      "  ...\n",
      "  [ 79  82  64]\n",
      "  [ 68  70  55]\n",
      "  [ 67  69  55]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[175 167 166]\n",
      "  [156 154 160]\n",
      "  [154 160 170]\n",
      "  ...\n",
      "  [ 42  34  36]\n",
      "  [ 61  53  57]\n",
      "  [ 93  83  91]]\n",
      "\n",
      " [[165 154 128]\n",
      "  [156 152 130]\n",
      "  [159 161 142]\n",
      "  ...\n",
      "  [103  93  96]\n",
      "  [123 114 120]\n",
      "  [131 121 131]]\n",
      "\n",
      " [[163 148 120]\n",
      "  [158 148 122]\n",
      "  [163 156 133]\n",
      "  ...\n",
      "  [143 133 139]\n",
      "  [143 134 142]\n",
      "  [143 133 144]]]\n"
     ]
    }
   ],
   "source": [
    "#We will now take a look at an individual image, lets look at the second image from the training set\n",
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb245e",
   "metadata": {},
   "source": [
    "Our kernel kept dying with the matplotlib image, so we are removing this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc9175",
   "metadata": {},
   "source": [
    "what we really want is the likelihood of each of the 10 classes. As such we will need 10 output neurons in the neural network. Since we have 10 output neurons, our labels must match as well. As such, we convert the label into a set of 10 numbers. Each number represents if the image belongs to that class or not. So if an image belongs to the first class, the first number of this set will be a 1 and all the other number sin this set will be a 0. To convert the labels to our one-hot encoding we will use a Keras function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f762199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one hot label is: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_train_one_hot = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print('The one hot label is:', y_train_one_hot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db5530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common step we do is to let the values to be between 0 and 1, which will aid in the training of our neural network. Since our pixel values already take the values between 0 and 255, we simply need to divide by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a99beed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23137255, 0.24313726, 0.24705882],\n",
       "        [0.16862746, 0.18039216, 0.1764706 ],\n",
       "        [0.19607843, 0.1882353 , 0.16862746],\n",
       "        ...,\n",
       "        [0.61960787, 0.5176471 , 0.42352942],\n",
       "        [0.59607846, 0.49019608, 0.4       ],\n",
       "        [0.5803922 , 0.4862745 , 0.40392157]],\n",
       "\n",
       "       [[0.0627451 , 0.07843138, 0.07843138],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.07058824, 0.03137255, 0.        ],\n",
       "        ...,\n",
       "        [0.48235294, 0.34509805, 0.21568628],\n",
       "        [0.46666667, 0.3254902 , 0.19607843],\n",
       "        [0.47843137, 0.34117648, 0.22352941]],\n",
       "\n",
       "       [[0.09803922, 0.09411765, 0.08235294],\n",
       "        [0.0627451 , 0.02745098, 0.        ],\n",
       "        [0.19215687, 0.10588235, 0.03137255],\n",
       "        ...,\n",
       "        [0.4627451 , 0.32941177, 0.19607843],\n",
       "        [0.47058824, 0.32941177, 0.19607843],\n",
       "        [0.42745098, 0.28627452, 0.16470589]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
       "        [0.7882353 , 0.6       , 0.13333334],\n",
       "        [0.7764706 , 0.6313726 , 0.10196079],\n",
       "        ...,\n",
       "        [0.627451  , 0.52156866, 0.27450982],\n",
       "        [0.21960784, 0.12156863, 0.02745098],\n",
       "        [0.20784314, 0.13333334, 0.07843138]],\n",
       "\n",
       "       [[0.7058824 , 0.54509807, 0.3764706 ],\n",
       "        [0.6784314 , 0.48235294, 0.16470589],\n",
       "        [0.7294118 , 0.5647059 , 0.11764706],\n",
       "        ...,\n",
       "        [0.72156864, 0.5803922 , 0.36862746],\n",
       "        [0.38039216, 0.24313726, 0.13333334],\n",
       "        [0.3254902 , 0.20784314, 0.13333334]],\n",
       "\n",
       "       [[0.69411767, 0.5647059 , 0.45490196],\n",
       "        [0.65882355, 0.5058824 , 0.36862746],\n",
       "        [0.7019608 , 0.5568628 , 0.34117648],\n",
       "        ...,\n",
       "        [0.84705883, 0.72156864, 0.54901963],\n",
       "        [0.5921569 , 0.4627451 , 0.32941177],\n",
       "        [0.48235294, 0.36078432, 0.28235295]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b0021",
   "metadata": {},
   "source": [
    "Here is the breakdown of the architecture that we will be using for this netwrok for its building and training: \n",
    "Conv Layer (Filter size 3x3, Depth 32)\n",
    "Conv Layer (Filter size 3x3, Depth 32)\n",
    "Max Pool Layer (Filter size 2x2)\n",
    "Dropout Layer (Prob of dropout 0.25)\n",
    "Conv Layer (Filter size 3x3, Depth 64)\n",
    "Conv Layer (Filter size 3x3, Depth 64)\n",
    "Max Pool Layer (Filter size 2x2)\n",
    "Dropout Layer (Prob of dropout 0.25)\n",
    "FC Layer (512 neurons)\n",
    "Dropout Layer (Prob of dropout 0.5)\n",
    "FC Layer, Softmax (10 neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c1b5bc",
   "metadata": {},
   "source": [
    "The first layer is a conv layer with filter size 3x3, stride size 1 (in both dimensions), and depth 32. The padding is the 'same' and the activation is 'relu' (these two settings will apply to all layers in our CNN). We add this layer to our empty sequential model using the function model.add().\n",
    "\n",
    "The first number 32 refers to the depth. The next pair of numbers (3,3) refer to the filter width and size. Then, we specify activation which is 'relu' and padding which is 'same'. Notice that we did not specify stride. This is because stride=1 is a default setting, and unless we want to change this setting, we need not specify it.\n",
    "\n",
    "If you recall, we also need to specify an input size for our first layer; subsequent layers does not have this specification since they can infer the input size from the output size of the previous layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66978293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32,32,3)))\n",
    "\n",
    "#second layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "#third layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#dopout layer\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "#and then our next four layers where the depth of conv layer is 64 rather than 32\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875267a5",
   "metadata": {},
   "source": [
    "Now we need to code our fully connected layer. But, our neurons are arranged i a cube format rather than a row, \n",
    "to condense them into a row, we will use a flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d76605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten())\n",
    "#and add a dense (FC) layer of 512 neurons in a relu activation\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#add dropout pobability of 0.5\n",
    "model.add(Dropout(0.5))\n",
    "#and we then have a dense (FC) layer with 10 neurons and a softmax activation\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#now we are done with specifying our architecture\n",
    "\n",
    "#lets see a summary of our architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefe95d",
   "metadata": {},
   "source": [
    "Now, we we fill in the best numbers post specification of architecture. We will copile th emodel with the settings below. The loss function is calle categorical cross entropy. Ths is applicable for a classification porblem of many classes. The optimizer is Adam. Adam is a type of stochastic gradient descent (with a few mods) so thay it trains better. We will also track the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8189829",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37003bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 59s 47ms/step - loss: 1.5953 - accuracy: 0.4128 - val_loss: 1.2389 - val_accuracy: 0.5631\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 56s 45ms/step - loss: 1.1818 - accuracy: 0.5766 - val_loss: 1.0133 - val_accuracy: 0.6526\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 58s 47ms/step - loss: 1.0093 - accuracy: 0.6435 - val_loss: 0.9122 - val_accuracy: 0.6740\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 56s 45ms/step - loss: 0.8996 - accuracy: 0.6836 - val_loss: 0.8149 - val_accuracy: 0.7145\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.8307 - accuracy: 0.7072 - val_loss: 0.7513 - val_accuracy: 0.7371\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 60s 48ms/step - loss: 0.7742 - accuracy: 0.7285 - val_loss: 0.7592 - val_accuracy: 0.7351\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 54s 43ms/step - loss: 0.7249 - accuracy: 0.7434 - val_loss: 0.7784 - val_accuracy: 0.7282\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 54s 43ms/step - loss: 0.6824 - accuracy: 0.7596 - val_loss: 0.7153 - val_accuracy: 0.7560\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 55s 44ms/step - loss: 0.6403 - accuracy: 0.7732 - val_loss: 0.6888 - val_accuracy: 0.7606\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 53s 42ms/step - loss: 0.6094 - accuracy: 0.7844 - val_loss: 0.7076 - val_accuracy: 0.7560\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 0.5779 - accuracy: 0.7963 - val_loss: 0.7174 - val_accuracy: 0.7574\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.5574 - accuracy: 0.8031 - val_loss: 0.7070 - val_accuracy: 0.7651\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.5324 - accuracy: 0.8110 - val_loss: 0.6887 - val_accuracy: 0.7693\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.5126 - accuracy: 0.8197 - val_loss: 0.6789 - val_accuracy: 0.7728\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4911 - accuracy: 0.8267 - val_loss: 0.6914 - val_accuracy: 0.7765\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4737 - accuracy: 0.8298 - val_loss: 0.6834 - val_accuracy: 0.7787\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4579 - accuracy: 0.8396 - val_loss: 0.6893 - val_accuracy: 0.7722\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.4427 - accuracy: 0.8451 - val_loss: 0.7166 - val_accuracy: 0.7763\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.4399 - accuracy: 0.8461 - val_loss: 0.6777 - val_accuracy: 0.7802\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.4250 - accuracy: 0.8519 - val_loss: 0.7238 - val_accuracy: 0.7742\n"
     ]
    }
   ],
   "source": [
    "#lets train with a batch of 32 and 20 epochs. The validation split will be set to 0.2 rather than validation_data\n",
    "#with this shortcut, we did not need to split our dataset into a train and validation set at the start.\n",
    "#rather , we will specify how much of our dataset will be used as a validation set. In this case\n",
    "# 20% of the dataset is used as a validation set. I am prepared for this to take a moment\n",
    "\n",
    "hist = model.fit(x_train, y_train_one_hot, \n",
    "           batch_size=32, epochs=20, \n",
    "           validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16e673b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.7740 - accuracy: 0.7671\n"
     ]
    }
   ],
   "source": [
    "#we are then going ot evaluate our model with our test set, and we are going to save our trained model\n",
    "\n",
    "model.evaluate(x_test, y_test_one_hot)[1]\n",
    "model.save('my_cifar10_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e4bdb",
   "metadata": {},
   "source": [
    "I will be omitting the image omparison portion of this assignment due to the fact the kernel keeps crashing when the matplotlib image interaction is called. We have our model trained and that works well. Possibilities include that perhaps we arein the wrong environment. Nonetheleless we have covered a lot of ground. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
